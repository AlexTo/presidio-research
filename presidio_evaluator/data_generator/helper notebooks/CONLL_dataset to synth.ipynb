{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the CONLL2003 dataset using deepavlov, and creates templates (utterances with placeholders) for a PII synthetic data generator to use in order to create new sentences.\n",
    "\n",
    "The notebook additionally introduces two new entities: TITLE and ROLE, in order to overcome cases like \"UK David Scott called his wife\", where the original sentence is \"UK Prime Minister Boris Johnson called his wife\" as \"Prime Minister\" was originally tagged as PER in the original dataset. Same logic goes for titles, like Mr., Mrs., Ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from deeppavlov.dataset_readers.conll2003_reader import Conll2003DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Conll2003DatasetReader()\n",
    "dataset = reader.read(data_path =\"../../data\",dataset_name='conll2003')\n",
    "#Note: make sure you haven't downloaded something else with this function before, \n",
    "# as it will not download a new dataset (even if your previous download was for a different dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Only',\n",
       "  'France',\n",
       "  'and',\n",
       "  'Britain',\n",
       "  'backed',\n",
       "  'Fischler',\n",
       "  \"'s\",\n",
       "  'proposal',\n",
       "  '.'],\n",
       " ['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-PER', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To pandas + add sentence_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = [list(zip(a,b)) for a,b in dataset['train']]\n",
    "df_list = []\n",
    "sentence_id = 0\n",
    "for sentence in new_dataset:\n",
    "   \n",
    "    df = pd.DataFrame(sentence,columns = [\"word\",\"tag\"])\n",
    "    df[\"sentence_idx\"] = sentence_id\n",
    "    sentence_id+=1\n",
    "    df_list.append(df)\n",
    "ner_dataset = pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ner_dataset.groupby('sentence_idx')['word'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only France and Britain backed Fischler 's proposal .\n"
     ]
    }
   ],
   "source": [
    "print(sentences[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Britain</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>backed</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fischler</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'s</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>proposal</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    tag  sentence_idx\n",
       "0  Only      O      12          \n",
       "1  France    B-LOC  12          \n",
       "2  and       O      12          \n",
       "3  Britain   B-LOC  12          \n",
       "4  backed    O      12          \n",
       "5  Fischler  B-PER  12          \n",
       "6  's        O      12          \n",
       "7  proposal  O      12          \n",
       "8  .         O      12          "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset[ner_dataset['sentence_idx']==12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-ORG', 'O', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG',\n",
       "       'I-MISC', 'I-LOC'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique entities\n",
    "ner_dataset['tag'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace tokenization replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset['word'] = ner_dataset['word']\\\n",
    ".replace('-LRB-','(')\\\n",
    ".replace('-RRB-',')')\\\n",
    ".replace('-LCB-','(')\\\n",
    ".replace('-RCB-',')')\\\n",
    ".replace('``','\"')\\\n",
    ".replace(\"''\",'\"')\\\n",
    ".replace('/.','.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper columns:\n",
    "ner_dataset['prev-word'] = ner_dataset.word.shift(1)\n",
    "ner_dataset['prev-prev-word'] = ner_dataset['word'].shift(2)\n",
    "ner_dataset['next-word'] = ner_dataset['word'].shift(-1)\n",
    "ner_dataset['next-next-word'] = ner_dataset['word'].shift(-2)\n",
    "ner_dataset['prev-tag'] = ner_dataset['tag'].shift(1)\n",
    "ner_dataset['next-tag'] = ner_dataset['tag'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>next-word</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>prev-tag</th>\n",
       "      <th>next-tag</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>.</td>\n",
       "      <td>year</td>\n",
       "      <td>new</td>\n",
       "      <td>coach</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>But</td>\n",
       "      <td>.</td>\n",
       "      <td>coach</td>\n",
       "      <td>Rolf</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coach</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>new</td>\n",
       "      <td>But</td>\n",
       "      <td>Rolf</td>\n",
       "      <td>Fringer</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rolf</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>900</td>\n",
       "      <td>coach</td>\n",
       "      <td>new</td>\n",
       "      <td>Fringer</td>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fringer</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>900</td>\n",
       "      <td>Rolf</td>\n",
       "      <td>coach</td>\n",
       "      <td>is</td>\n",
       "      <td>clearly</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>Fringer</td>\n",
       "      <td>Rolf</td>\n",
       "      <td>clearly</td>\n",
       "      <td>a</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clearly</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>is</td>\n",
       "      <td>Fringer</td>\n",
       "      <td>a</td>\n",
       "      <td>Knup</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>clearly</td>\n",
       "      <td>is</td>\n",
       "      <td>Knup</td>\n",
       "      <td>fan</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Knup</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>900</td>\n",
       "      <td>a</td>\n",
       "      <td>clearly</td>\n",
       "      <td>fan</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fan</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>Knup</td>\n",
       "      <td>a</td>\n",
       "      <td>and</td>\n",
       "      <td>included</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>fan</td>\n",
       "      <td>Knup</td>\n",
       "      <td>included</td>\n",
       "      <td>him</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>included</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>and</td>\n",
       "      <td>fan</td>\n",
       "      <td>him</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>him</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>included</td>\n",
       "      <td>and</td>\n",
       "      <td>in</td>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>him</td>\n",
       "      <td>included</td>\n",
       "      <td>his</td>\n",
       "      <td>19-man</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>in</td>\n",
       "      <td>him</td>\n",
       "      <td>19-man</td>\n",
       "      <td>squad</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19-man</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>his</td>\n",
       "      <td>in</td>\n",
       "      <td>squad</td>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>squad</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>19-man</td>\n",
       "      <td>his</td>\n",
       "      <td>on</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>squad</td>\n",
       "      <td>19-man</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>on</td>\n",
       "      <td>squad</td>\n",
       "      <td>.</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>900</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>on</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>failed</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    tag  sentence_idx prev-word prev-prev-word    next-word  \\\n",
       "0   But       O      900           .         year           new           \n",
       "1   new       O      900           But       .              coach         \n",
       "2   coach     O      900           new       But            Rolf          \n",
       "3   Rolf      B-PER  900           coach     new            Fringer       \n",
       "4   Fringer   I-PER  900           Rolf      coach          is            \n",
       "5   is        O      900           Fringer   Rolf           clearly       \n",
       "6   clearly   O      900           is        Fringer        a             \n",
       "7   a         O      900           clearly   is             Knup          \n",
       "8   Knup      B-PER  900           a         clearly        fan           \n",
       "9   fan       O      900           Knup      a              and           \n",
       "10  and       O      900           fan       Knup           included      \n",
       "11  included  O      900           and       fan            him           \n",
       "12  him       O      900           included  and            in            \n",
       "13  in        O      900           him       included       his           \n",
       "14  his       O      900           in        him            19-man        \n",
       "15  19-man    O      900           his       in             squad         \n",
       "16  squad     O      900           19-man    his            on            \n",
       "17  on        O      900           squad     19-man         Thursday      \n",
       "18  Thursday  O      900           on        squad          .             \n",
       "19  .         O      900           Thursday  on             Switzerland   \n",
       "\n",
       "   next-next-word prev-tag next-tag metadata  \n",
       "0   coach          O        O        None     \n",
       "1   Rolf           O        O        None     \n",
       "2   Fringer        O        B-PER    None     \n",
       "3   is             O        I-PER    None     \n",
       "4   clearly        B-PER    O        None     \n",
       "5   a              I-PER    O        None     \n",
       "6   Knup           O        O        None     \n",
       "7   fan            O        B-PER    None     \n",
       "8   and            O        O        None     \n",
       "9   included       B-PER    O        None     \n",
       "10  him            O        O        None     \n",
       "11  in             O        O        None     \n",
       "12  his            O        O        None     \n",
       "13  19-man         O        O        None     \n",
       "14  squad          O        O        None     \n",
       "15  on             O        O        None     \n",
       "16  Thursday       O        O        None     \n",
       "17  .              O        O        None     \n",
       "18  Switzerland    O        O        None     \n",
       "19  failed         O        B-LOC    None     "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset[ner_dataset['sentence_idx']==900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG',\n",
       "       'I-PER', 'O'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ner_dataset['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unneeded (non PII) entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>next-word</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>prev-tag</th>\n",
       "      <th>next-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>1996-08-22</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>European</td>\n",
       "      <td>Commission</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>The</td>\n",
       "      <td>1996-08-22</td>\n",
       "      <td>Commission</td>\n",
       "      <td>said</td>\n",
       "      <td>O</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commission</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>European</td>\n",
       "      <td>The</td>\n",
       "      <td>said</td>\n",
       "      <td>on</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>Commission</td>\n",
       "      <td>European</td>\n",
       "      <td>on</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>said</td>\n",
       "      <td>Commission</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>it</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>on</td>\n",
       "      <td>said</td>\n",
       "      <td>it</td>\n",
       "      <td>disagreed</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>on</td>\n",
       "      <td>disagreed</td>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disagreed</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>it</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>with</td>\n",
       "      <td>German</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>disagreed</td>\n",
       "      <td>it</td>\n",
       "      <td>German</td>\n",
       "      <td>advice</td>\n",
       "      <td>O</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>German</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>with</td>\n",
       "      <td>disagreed</td>\n",
       "      <td>advice</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>advice</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>German</td>\n",
       "      <td>with</td>\n",
       "      <td>to</td>\n",
       "      <td>consumers</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>advice</td>\n",
       "      <td>German</td>\n",
       "      <td>consumers</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>consumers</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>to</td>\n",
       "      <td>advice</td>\n",
       "      <td>to</td>\n",
       "      <td>shun</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>consumers</td>\n",
       "      <td>to</td>\n",
       "      <td>shun</td>\n",
       "      <td>British</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shun</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>to</td>\n",
       "      <td>consumers</td>\n",
       "      <td>British</td>\n",
       "      <td>lamb</td>\n",
       "      <td>O</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>British</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>shun</td>\n",
       "      <td>to</td>\n",
       "      <td>lamb</td>\n",
       "      <td>until</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lamb</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>British</td>\n",
       "      <td>shun</td>\n",
       "      <td>until</td>\n",
       "      <td>scientists</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>until</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>lamb</td>\n",
       "      <td>British</td>\n",
       "      <td>scientists</td>\n",
       "      <td>determine</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>scientists</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>until</td>\n",
       "      <td>lamb</td>\n",
       "      <td>determine</td>\n",
       "      <td>whether</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>determine</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>scientists</td>\n",
       "      <td>until</td>\n",
       "      <td>whether</td>\n",
       "      <td>mad</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>whether</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>determine</td>\n",
       "      <td>scientists</td>\n",
       "      <td>mad</td>\n",
       "      <td>cow</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mad</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>whether</td>\n",
       "      <td>determine</td>\n",
       "      <td>cow</td>\n",
       "      <td>disease</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cow</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>mad</td>\n",
       "      <td>whether</td>\n",
       "      <td>disease</td>\n",
       "      <td>can</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>disease</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>cow</td>\n",
       "      <td>mad</td>\n",
       "      <td>can</td>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>can</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>disease</td>\n",
       "      <td>cow</td>\n",
       "      <td>be</td>\n",
       "      <td>transmitted</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>can</td>\n",
       "      <td>disease</td>\n",
       "      <td>transmitted</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transmitted</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>be</td>\n",
       "      <td>can</td>\n",
       "      <td>to</td>\n",
       "      <td>sheep</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>transmitted</td>\n",
       "      <td>be</td>\n",
       "      <td>sheep</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sheep</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>to</td>\n",
       "      <td>transmitted</td>\n",
       "      <td>.</td>\n",
       "      <td>Germany</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>sheep</td>\n",
       "      <td>to</td>\n",
       "      <td>Germany</td>\n",
       "      <td>'s</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word    tag  sentence_idx    prev-word prev-prev-word    next-word  \\\n",
       "0   The          O      3             1996-08-22   BRUSSELS       European      \n",
       "1   European     B-ORG  3             The          1996-08-22     Commission    \n",
       "2   Commission   I-ORG  3             European     The            said          \n",
       "3   said         O      3             Commission   European       on            \n",
       "4   on           O      3             said         Commission     Thursday      \n",
       "5   Thursday     O      3             on           said           it            \n",
       "6   it           O      3             Thursday     on             disagreed     \n",
       "7   disagreed    O      3             it           Thursday       with          \n",
       "8   with         O      3             disagreed    it             German        \n",
       "9   German       O      3             with         disagreed      advice        \n",
       "10  advice       O      3             German       with           to            \n",
       "11  to           O      3             advice       German         consumers     \n",
       "12  consumers    O      3             to           advice         to            \n",
       "13  to           O      3             consumers    to             shun          \n",
       "14  shun         O      3             to           consumers      British       \n",
       "15  British      O      3             shun         to             lamb          \n",
       "16  lamb         O      3             British      shun           until         \n",
       "17  until        O      3             lamb         British        scientists    \n",
       "18  scientists   O      3             until        lamb           determine     \n",
       "19  determine    O      3             scientists   until          whether       \n",
       "20  whether      O      3             determine    scientists     mad           \n",
       "21  mad          O      3             whether      determine      cow           \n",
       "22  cow          O      3             mad          whether        disease       \n",
       "23  disease      O      3             cow          mad            can           \n",
       "24  can          O      3             disease      cow            be            \n",
       "25  be           O      3             can          disease        transmitted   \n",
       "26  transmitted  O      3             be           can            to            \n",
       "27  to           O      3             transmitted  be             sheep         \n",
       "28  sheep        O      3             to           transmitted    .             \n",
       "29  .            O      3             sheep        to             Germany       \n",
       "\n",
       "   next-next-word prev-tag next-tag  \n",
       "0   Commission     O        B-ORG    \n",
       "1   said           O        I-ORG    \n",
       "2   on             B-ORG    O        \n",
       "3   Thursday       I-ORG    O        \n",
       "4   it             O        O        \n",
       "5   disagreed      O        O        \n",
       "6   with           O        O        \n",
       "7   German         O        O        \n",
       "8   advice         O        B-MISC   \n",
       "9   to             O        O        \n",
       "10  consumers      B-MISC   O        \n",
       "11  to             O        O        \n",
       "12  shun           O        O        \n",
       "13  British        O        O        \n",
       "14  lamb           O        B-MISC   \n",
       "15  until          O        O        \n",
       "16  scientists     B-MISC   O        \n",
       "17  determine      O        O        \n",
       "18  whether        O        O        \n",
       "19  mad            O        O        \n",
       "20  cow            O        O        \n",
       "21  disease        O        O        \n",
       "22  can            O        O        \n",
       "23  be             O        O        \n",
       "24  transmitted    O        O        \n",
       "25  to             O        O        \n",
       "26  sheep          O        O        \n",
       "27  .              O        O        \n",
       "28  Germany        O        O        \n",
       "29  's             O        B-LOC    "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAGS_TO_IGNORE = ['CARDINAL','FAC','LAW','LANGUAGE','MISC','TIME','DATE','ORDINAL','EVENT','QUANTITY','WORK_OF_ART','MONEY','PRODUCT','PERCENT']\n",
    "def remote_unwanted_tags(x):\n",
    "    if len(x)>1 and x[2:] in TAGS_TO_IGNORE:\n",
    "        return 'O'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "ner_dataset['tag'] = ner_dataset['tag'].apply(remote_unwanted_tags)\n",
    "ner_dataset[ner_dataset['sentence_idx']==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove PERSON tags if preceding word is 'the' (e.g. the Bush administration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing PERSON tags from sentences with a 'the' preceding the person:\n",
    "\n",
    "def remove_tag_if_the_person(row):\n",
    "    if row['prev-word'].lower() == 'the' and row['tag']=='B-PERSON':\n",
    "        return 'O'\n",
    "    elif row['prev-prev-word'].lower() == 'the' and row['prev-tag']=='I-PERSON' and row['tag']=='B-PERSON':\n",
    "        return 'O'\n",
    "    return row['tag']\n",
    "\n",
    "ner_dataset['prev-word']=ner_dataset['prev-word'].astype('str')\n",
    "ner_dataset['prev-prev-word']=ner_dataset['prev-prev-word'].astype('str')\n",
    "ner_dataset['tag'] = ner_dataset.apply(remove_tag_if_the_person,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove tag from 's (Joe Wilson's cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tag_if_apostraphe_after_tag(row):\n",
    "    if row['prev-tag'] != 'O' and row['word']==\"'s\":\n",
    "        return 'O'\n",
    "    return row['tag']\n",
    "ner_dataset['tag'] = ner_dataset.apply(remove_tag_if_the_person,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-tag words from dictionaries (countries, nationalities, roles, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nationalities and countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>nationality</th>\n",
       "      <th>man</th>\n",
       "      <th>woman</th>\n",
       "      <th>plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>algeria</td>\n",
       "      <td>algerian</td>\n",
       "      <td>algerian</td>\n",
       "      <td>algerian</td>\n",
       "      <td>algerians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andorra</td>\n",
       "      <td>andorran</td>\n",
       "      <td>andorran</td>\n",
       "      <td>andorran</td>\n",
       "      <td>andorrans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angola</td>\n",
       "      <td>angolan</td>\n",
       "      <td>angolan</td>\n",
       "      <td>angolan</td>\n",
       "      <td>angolans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argentina</td>\n",
       "      <td>argentinian</td>\n",
       "      <td>argentinian</td>\n",
       "      <td>argentinian</td>\n",
       "      <td>argentinians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>armenia</td>\n",
       "      <td>armenian</td>\n",
       "      <td>armenian</td>\n",
       "      <td>armenian</td>\n",
       "      <td>armenians</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country  nationality          man        woman        plural\n",
       "0  algeria    algerian     algerian     algerian     algerians   \n",
       "1  andorra    andorran     andorran     andorran     andorrans   \n",
       "2  angola     angolan      angolan      angolan      angolans    \n",
       "3  argentina  argentinian  argentinian  argentinian  argentinians\n",
       "4  armenia    armenian     armenian     armenian     armenians   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationalities = pd.read_csv(\"../raw_data/nationalities.csv\")\n",
    "nationalities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"algeria\" in nationalities['country'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Frenchwoman ->  NATION_WOMAN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_dataset['metadata'] = None\n",
    "\n",
    "def get_nationality_as_metadata(row):\n",
    "    if row['word'].lower() in nationalities['country'].values:\n",
    "        return 'COUNTRY'\n",
    "    elif row['word'].lower() in nationalities['nationality'].values:\n",
    "        return 'NATIONALITY'\n",
    "    elif row['word'].lower() in nationalities['man'].values:\n",
    "        return 'NATION_MAN'\n",
    "    elif row['word'].lower() in nationalities['woman'].values:\n",
    "        return 'NATION_WOMAN'\n",
    "    elif row['word'].lower() in nationalities['plural'].values:\n",
    "        return 'NATION_PLURAL'\n",
    "    return row['metadata']\n",
    "\n",
    "row = pd.Series({'word':'Frenchwoman','metadata':None})\n",
    "print(\"Example: Frenchwoman -> \",get_nationality_as_metadata(row))\n",
    "\n",
    "def update_tag_based_on_metadata(row):\n",
    "    if row['metadata'] is not None:\n",
    "        return \"B-\"+row['metadata']\n",
    "    else:\n",
    "        return row['tag']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset['metadata'] = ner_dataset.apply(get_nationality_as_metadata, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None       \n",
       "1    None       \n",
       "2    NATIONALITY\n",
       "3    None       \n",
       "4    None       \n",
       "     ...        \n",
       "1    None       \n",
       "0    None       \n",
       "1    None       \n",
       "2    None       \n",
       "3    None       \n",
       "Name: metadata, Length: 203621, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MALE_TITLES = ['mr', 'dr', 'professor', 'eng','prof','doctor']\n",
    "FEMALE_TITLES = ['mrs', 'ms', 'miss', 'dr', 'professor', 'eng', 'prof','doctor']\n",
    "\n",
    "def get_title_as_metadata(row):\n",
    "    if row['word'].lower() in MALE_TITLES:\n",
    "        return 'MALE_TITLE'\n",
    "    elif row['word'].lower() in FEMALE_TITLES:\n",
    "        return 'FEMALE_TITLE'\n",
    "    return row['metadata']\n",
    "\n",
    "\n",
    "def update_title_tag_if_missing(row):\n",
    "    if row['word'].lower() in MALE_TITLES and row['tag']=='O':\n",
    "        return 'B-MALE_TITLE'\n",
    "    elif row['word'].lower() in FEMALE_TITLES and row['tag']=='O':\n",
    "        return 'B-FEMALE_TITLE'\n",
    "    else:\n",
    "        return row['tag']\n",
    "\n",
    "ner_dataset['metadata'] = ner_dataset.apply(get_title_as_metadata,axis=1)\n",
    "ner_dataset['tag'] = ner_dataset.apply(update_title_tag_if_missing,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>next-word</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>prev-tag</th>\n",
       "      <th>next-tag</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>18</td>\n",
       "      <td>.</td>\n",
       "      <td>beef</td>\n",
       "      <td>imported</td>\n",
       "      <td>47,600</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>COUNTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imported</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>Germany</td>\n",
       "      <td>.</td>\n",
       "      <td>47,600</td>\n",
       "      <td>sheep</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47,600</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>imported</td>\n",
       "      <td>Germany</td>\n",
       "      <td>sheep</td>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sheep</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>47,600</td>\n",
       "      <td>imported</td>\n",
       "      <td>from</td>\n",
       "      <td>Britain</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>sheep</td>\n",
       "      <td>47,600</td>\n",
       "      <td>Britain</td>\n",
       "      <td>last</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Britain</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>18</td>\n",
       "      <td>from</td>\n",
       "      <td>sheep</td>\n",
       "      <td>last</td>\n",
       "      <td>year</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>COUNTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>last</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>Britain</td>\n",
       "      <td>from</td>\n",
       "      <td>year</td>\n",
       "      <td>,</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>last</td>\n",
       "      <td>Britain</td>\n",
       "      <td>,</td>\n",
       "      <td>nearly</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>year</td>\n",
       "      <td>last</td>\n",
       "      <td>nearly</td>\n",
       "      <td>half</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nearly</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>,</td>\n",
       "      <td>year</td>\n",
       "      <td>half</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>half</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>nearly</td>\n",
       "      <td>,</td>\n",
       "      <td>of</td>\n",
       "      <td>total</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>half</td>\n",
       "      <td>nearly</td>\n",
       "      <td>total</td>\n",
       "      <td>imports</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>of</td>\n",
       "      <td>half</td>\n",
       "      <td>imports</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>imports</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>total</td>\n",
       "      <td>of</td>\n",
       "      <td>.</td>\n",
       "      <td>It</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>18</td>\n",
       "      <td>imports</td>\n",
       "      <td>total</td>\n",
       "      <td>It</td>\n",
       "      <td>brought</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word    tag  sentence_idx prev-word prev-prev-word next-word  \\\n",
       "0   Germany   B-LOC  18            .         beef           imported   \n",
       "1   imported  O      18            Germany   .              47,600     \n",
       "2   47,600    O      18            imported  Germany        sheep      \n",
       "3   sheep     O      18            47,600    imported       from       \n",
       "4   from      O      18            sheep     47,600         Britain    \n",
       "5   Britain   B-LOC  18            from      sheep          last       \n",
       "6   last      O      18            Britain   from           year       \n",
       "7   year      O      18            last      Britain        ,          \n",
       "8   ,         O      18            year      last           nearly     \n",
       "9   nearly    O      18            ,         year           half       \n",
       "10  half      O      18            nearly    ,              of         \n",
       "11  of        O      18            half      nearly         total      \n",
       "12  total     O      18            of        half           imports    \n",
       "13  imports   O      18            total     of             .          \n",
       "14  .         O      18            imports   total          It         \n",
       "\n",
       "   next-next-word prev-tag next-tag metadata  \n",
       "0   47,600         O        O        COUNTRY  \n",
       "1   sheep          B-LOC    O        None     \n",
       "2   from           O        O        None     \n",
       "3   Britain        O        O        None     \n",
       "4   last           O        B-LOC    None     \n",
       "5   year           O        O        COUNTRY  \n",
       "6   ,              B-LOC    O        None     \n",
       "7   nearly         O        O        None     \n",
       "8   half           O        O        None     \n",
       "9   of             O        O        None     \n",
       "10  total          O        O        None     \n",
       "11  imports        O        O        None     \n",
       "12  .              O        O        None     \n",
       "13  It             O        O        None     \n",
       "14  brought        O        O        None     "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset[ner_dataset['sentence_idx']==18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 'the' from 'the NORP' if NORP is not in nationalities list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tag_if_the_norp(row):\n",
    "    if row['prev-word'].lower() == 'the' and row['tag']=='B-NORP' and row['metadata'] is None:\n",
    "        return 'O'\n",
    "    elif row['prev-prev-word'].lower() == 'the' and row['prev-tag']=='I-NORP' and row['tag']=='B-NORP' and row['metadata'] is None:\n",
    "        return 'O'\n",
    "    return row['tag']\n",
    "ner_dataset['tag'] = ner_dataset.apply(remove_tag_if_the_norp,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove sentences with adjacent different entities (e.g calling from New York Larry King)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset['entity'] = ner_dataset['tag'].str[2:]\n",
    "ner_dataset['next-entity']=ner_dataset['next-tag'].str[2:]\n",
    "adjacent_idc = (ner_dataset['tag'] != 'O') & (ner_dataset['next-tag'] != 'O') & (ner_dataset['entity'] != ner_dataset['next-entity'])\n",
    "sentences_to_remove = ner_dataset[adjacent_idc]['sentence_idx'].values\n",
    "sentences_to_remove\n",
    "\n",
    "ner_dataset=ner_dataset[~ner_dataset['sentence_idx'].isin(sentences_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update tag for discovered metadata values (eg. nationalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset['tag'] = ner_dataset.apply(update_tag_based_on_metadata, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COUNTRY', 'FEMALE_TITLE', 'MALE_TITLE', 'NATIONALITY',\n",
       "       'NATION_MAN', 'NATION_PLURAL'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ner_dataset['metadata'][ner_dataset['metadata'].values != None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-FEMALE_TITLE', 'B-LOC', 'B-MALE_TITLE', 'B-ORG', 'B-PER',\n",
       "       'I-LOC', 'I-ORG', 'I-PER', 'O'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ner_dataset['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create templates base on NER dataset\n",
    "Here we create the actual templates + handle multiple weird cases that should cause the template sentences to be weird. Note that a manual run over the templates dataset is still required after this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    @staticmethod    \n",
    "    def cleanse_template(template, ents):\n",
    "        # Remove whitespace before certain punctuation marks\n",
    "        template = re.sub(r'\\s([?,:.!](?:|$))+', r'\\1', template)\n",
    "        \n",
    "        # Remove whitespaces within double quotes\n",
    "        template = re.sub('\\\"\\s*([^\\\"]*?)\\s*\\\"', r'\"\\1\"', template)    \n",
    "        \n",
    "        # Remove whitespaces within quotes\n",
    "        template = re.sub(\"\\'\\s*([^\\']*?)\\s*\\'\", r\"'\\1'\", template)    \n",
    "        \n",
    "        # Remove whitespaces within parentheses\n",
    "        template = re.sub('\\(\\s*([^\\(]*?)\\s*\\)', r'(\\1)', template)    \n",
    "        \n",
    "        for ent in ents:\n",
    "            #Turn PERSON PERSON into PERSON\n",
    "            duplicates = \"[{}] [{}]\".format(ent,ent)\n",
    "            template = template.replace(duplicates,\"[{}]\".format(ent))\n",
    "        \n",
    "        \n",
    "        # Replace additional weird templates:\n",
    "        to_replace = {\n",
    "            \"[LOCATION] says\" : \"[PERSON] says\",\n",
    "            \"[LOCATION] said\" : \"[PERSON] said\",\n",
    "            \"[ORGANIZATION] of [ORGANIZATION]\" : \"[ORGANIZATION]\",\n",
    "            \"the [COUNTRY]\" : \"[COUNTRY]\",\n",
    "            \" 's \":\"'s\",\n",
    "            \"] 's \":\"]'s \",\n",
    "            \"] 's,\":\"]'s,\",\n",
    "            \"] 's.\":\"]'s.\",\n",
    "            \" n't\" : \"n't\",\n",
    "            \"/?\":\"?\",\n",
    "            \"%u\":\"u\",\n",
    "            \"%m\":\"m\",\n",
    "            \"%e\":\"e\",  \n",
    "            \"%h\":\"h\",  \n",
    "            \"%a\":\"a\",\n",
    "            \" %\":\"%\",\n",
    "            \" ?\":\"?\",\n",
    "            \" /?\":\"?\",\n",
    "            \" ' .\":\"'.\",\n",
    "            \"[ \":\"(\",\n",
    "            \" ]\":\")\",\n",
    "            \"[PERSON] -- [PERSON]\":\"[PERSON]\",\n",
    "            \"[COUNTRY] -- [ORGANIZATION]\":\"[ORGANIZATION]\",\n",
    "            \"Jews\" : \"[NATIONALITY]\",\n",
    "            \"Chinese\" : \"[NATIONALITY]\",\n",
    "            \"Dutch\" : \"[NATIONALITY]\",\n",
    "            \"[LOCATION], [LOCATION]\":\"[LOCATION]\",\n",
    "            \"[LOCATION] [ORGANIZATION]\":\"[ORGANIZATION]\"\n",
    "        }\n",
    "        \n",
    "        for weird in to_replace.keys():\n",
    "            #if weird in template:\n",
    "            #    print(\"Weird sentence\",template)\n",
    "            template = template.replace(weird,to_replace[weird])\n",
    "  \n",
    "        template = template.replace(\" -- \",\" - \")\n",
    "        \n",
    "        #Ignore templates that are incomplete\n",
    "        if \"/-\" in template:\n",
    "            template = \"\"\n",
    "            \n",
    "        #Ignore templates that have numbers after the end or start of the entity\n",
    "        if len(re.findall(r\"\\]\\s[0-9]\",template)) > 0:\n",
    "            template = \"\"\n",
    "            \n",
    "        if len(re.findall(r\"[0-9]\\s\\[\",template)) > 0:\n",
    "            template = \"\"\n",
    "            \n",
    "        if len(re.findall(r\"[0-9].\\s\\[\",template)) > 0:\n",
    "            template = \"\"\n",
    "            \n",
    "            \n",
    "        if \"[PERSON] ([COUNTRY])\" in template:\n",
    "            template = \"\"\n",
    "        if \"[PERSON] ([LOCATION])\" in template:\n",
    "            template = \"\"\n",
    "            \n",
    "        if template.count('\"') == 1:\n",
    "            template = template.replace('\"','')\n",
    "\n",
    "        return template\n",
    "    \n",
    "    @staticmethod    \n",
    "    def get_template(grouped,entity_name_replace_dict):\n",
    "        template = \"\"\n",
    "        i=0\n",
    "        cur_index = 0\n",
    "        ents = []\n",
    "        for token in grouped:\n",
    "            # remove brackets as they interefere with the data generation process\n",
    "            token_text = token[0].replace(\"[\", \"(\").replace(\"]\",\")\")\n",
    "            token_text = token[0].replace(\"{\", \"(\").replace(\"}\",\")\")\n",
    "            token_tag = token[1]\n",
    "            token_entity = token_tag[2:] if len(token_tag)>1 else token_tag\n",
    "            \n",
    "            if token_entity == 'O':\n",
    "                template += \" \" + token_text\n",
    "            elif 'B-' in token_tag and token_entity not in TAGS_TO_IGNORE:\n",
    "                #print(\"found entity: {}\".format(token_entity))\n",
    "                ent = entity_name_replace_dict[token_entity]\n",
    "                ents.append(ent)\n",
    "                 \n",
    "                template += \" [\" + ent + \"]\"\n",
    "            #print(\"template: \",template)\n",
    "        \n",
    "        template = SentenceGetter.cleanse_template(template, ents)\n",
    "        \n",
    "        return template.strip()\n",
    "    \n",
    "getter = SentenceGetter(ner_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [('I.', 'B-PER'), ('Salisbury', 'I-PER'), ('not', 'O'), ('out', 'O'), ('1', 'O')]\n",
      "template: [PERSON] not out 1\n"
     ]
    }
   ],
   "source": [
    "ENTITIES_DICTIONARY = {\"PERSON\":\"PERSON\",\n",
    "                       \"PER\":\"PERSON\",\n",
    "                       \"GPE\":\"COUNTRY\",\n",
    "                       \"NORP\":\"LOCATION\",\n",
    "                       \"LOC\":\"LOCATION\",\n",
    "                       \"ORG\":\"ORGANIZATION\",\n",
    "                       \"MALE_TITLE\":\"MALE_TITLE\",\n",
    "                       \"FEMALE_TITLE\":\"FEMALE_TITLE\",\n",
    "                       \"COUNTRY\":\"COUNTRY\",\n",
    "                       \"NATIONALITY\":\"NATIONALITY\",\n",
    "                       \"NATION_WOMAN\":\"NATION_WOMAN\",\n",
    "                       \"NATION_MAN\":\"NATION_MAN\",\n",
    "                       \"NATION_PLURAL\":\"NATION_PLURAL\"}\n",
    "\n",
    "sentences = getter.sentences\n",
    "\n",
    "sent_id = 445\n",
    "\n",
    "print(\"original:\",sentences[sent_id])\n",
    "print(\"template:\", getter.get_template(sentences[sent_id],entity_name_replace_dict=ENTITIES_DICTIONARY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_templates = [getter.get_template(sentence,entity_name_replace_dict=ENTITIES_DICTIONARY) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length of templates: 13775\n",
      "length after duplicates removal: 8566\n"
     ]
    }
   ],
   "source": [
    "print(\"original length of templates: {}\".format(len(all_templates)))\n",
    "all_templates = list(set(all_templates))\n",
    "print(\"length after duplicates removal: {}\".format(len(all_templates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save templates to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../raw_data/conll_based_templates.txt\",\"w+\",encoding='utf-8') as f:\n",
    "    for template in all_templates:\n",
    "        f.write(\"%s\\n\" % template)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
